{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZHbaTAkJiZR",
        "outputId": "e1a56688-5457-44d9-ad2a-ed877cd08149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'uci_id': 31, 'name': 'Covertype', 'repository_url': 'https://archive.ics.uci.edu/dataset/31/covertype', 'data_url': 'https://archive.ics.uci.edu/static/public/31/data.csv', 'abstract': 'Classification of pixels into 7 forest cover types based on attributes such as elevation, aspect, slope, hillshade, soil-type, and more.', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 581012, 'num_features': 54, 'feature_types': ['Categorical', 'Integer'], 'demographics': [], 'target_col': ['Cover_Type'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1998, 'last_updated': 'Sat Mar 16 2024', 'dataset_doi': '10.24432/C50K5N', 'creators': ['Jock Blackard'], 'intro_paper': None, 'additional_info': {'summary': 'Predicting forest cover type from cartographic variables only (no remotely sensed data).  The actual forest cover type for a given observation (30 x 30 meter cell) was determined from US Forest Service (USFS) Region 2 Resource Information System (RIS) data.  Independent variables were derived from data originally obtained from US Geological Survey (USGS) and USFS data.  Data is in raw form (not scaled) and contains binary (0 or 1) columns of data for qualitative independent variables (wilderness areas and soil types).\\r\\n\\r\\nThis study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado.  These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices.\\r\\n\\r\\nSome background information for these four wilderness areas: Neota (area 2) probably has the highest mean elevational value of the 4 wilderness areas. Rawah (area 1) and Comanche Peak (area 3) would have a lower mean elevational value, while Cache la Poudre (area 4) would have the lowest mean elevational value. \\r\\n\\r\\nAs for primary major tree species in these areas, Neota would have spruce/fir (type 1), while Rawah and Comanche Peak would probably have lodgepole pine (type 2) as their primary species, followed by spruce/fir and aspen (type 5). Cache la Poudre would tend to have Ponderosa pine (type 3), Douglas-fir (type 6), and cottonwood/willow (type 4).  \\r\\n\\r\\nThe Rawah and Comanche Peak areas would tend to be more typical of the overall dataset than either the Neota or Cache la Poudre, due to their assortment of tree species and range of predictive variable values (elevation, etc.)  Cache la Poudre would probably  be more unique than the others, due to its relatively low  elevation range and species composition. ', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Given is the attribute name, attribute type, the measurement unit and a brief description.  The forest cover type is the classification  problem.  The order of this listing corresponds to the order of numerals along the rows of the database.\\r\\n\\r\\nName / Data Type / Measurement / Description\\r\\n\\r\\nElevation / quantitative /meters / Elevation in meters\\r\\nAspect / quantitative / azimuth / Aspect in degrees azimuth\\r\\nSlope / quantitative / degrees / Slope in degrees\\r\\nHorizontal_Distance_To_Hydrology / quantitative / meters / Horz Dist to nearest surface water features\\r\\nVertical_Distance_To_Hydrology / quantitative / meters / Vert Dist to nearest surface water features\\r\\nHorizontal_Distance_To_Roadways / quantitative / meters / Horz Dist to nearest roadway\\r\\nHillshade_9am / quantitative / 0 to 255 index / Hillshade index at 9am, summer solstice\\r\\nHillshade_Noon / quantitative / 0 to 255 index / Hillshade index at noon, summer soltice\\r\\nHillshade_3pm / quantitative / 0 to 255 index / Hillshade index at 3pm, summer solstice\\r\\nHorizontal_Distance_To_Fire_Points / quantitative / meters / Horz Dist to nearest wildfire ignition points\\r\\nWilderness_Area (4 binary columns) / qualitative / 0 (absence) or 1 (presence) / Wilderness area designation\\r\\nSoil_Type (40 binary columns) / qualitative / 0 (absence) or 1 (presence) / Soil Type designation\\r\\nCover_Type (7 types) / integer / 1 to 7 / Forest Cover Type designation', 'citation': None}}\n",
            "                                  name     role     type demographic  \\\n",
            "0                            Elevation  Feature  Integer        None   \n",
            "1                               Aspect  Feature  Integer        None   \n",
            "2                                Slope  Feature  Integer        None   \n",
            "3     Horizontal_Distance_To_Hydrology  Feature  Integer        None   \n",
            "4       Vertical_Distance_To_Hydrology  Feature  Integer        None   \n",
            "5      Horizontal_Distance_To_Roadways  Feature  Integer        None   \n",
            "6                        Hillshade_9am  Feature  Integer        None   \n",
            "7                       Hillshade_Noon  Feature  Integer        None   \n",
            "8                        Hillshade_3pm  Feature  Integer        None   \n",
            "9   Horizontal_Distance_To_Fire_Points  Feature  Integer        None   \n",
            "10                    Wilderness_Area1  Feature  Integer        None   \n",
            "11                          Soil_Type1  Feature  Integer        None   \n",
            "12                          Soil_Type2  Feature  Integer        None   \n",
            "13                          Soil_Type3  Feature  Integer        None   \n",
            "14                          Soil_Type4  Feature  Integer        None   \n",
            "15                          Soil_Type5  Feature  Integer        None   \n",
            "16                          Soil_Type6  Feature  Integer        None   \n",
            "17                          Soil_Type7  Feature  Integer        None   \n",
            "18                          Soil_Type8  Feature  Integer        None   \n",
            "19                          Soil_Type9  Feature  Integer        None   \n",
            "20                         Soil_Type10  Feature  Integer        None   \n",
            "21                         Soil_Type11  Feature  Integer        None   \n",
            "22                         Soil_Type12  Feature  Integer        None   \n",
            "23                         Soil_Type13  Feature  Integer        None   \n",
            "24                         Soil_Type14  Feature  Integer        None   \n",
            "25                         Soil_Type15  Feature  Integer        None   \n",
            "26                         Soil_Type16  Feature  Integer        None   \n",
            "27                         Soil_Type17  Feature  Integer        None   \n",
            "28                         Soil_Type18  Feature  Integer        None   \n",
            "29                         Soil_Type19  Feature  Integer        None   \n",
            "30                         Soil_Type20  Feature  Integer        None   \n",
            "31                         Soil_Type21  Feature  Integer        None   \n",
            "32                         Soil_Type22  Feature  Integer        None   \n",
            "33                         Soil_Type23  Feature  Integer        None   \n",
            "34                         Soil_Type24  Feature  Integer        None   \n",
            "35                         Soil_Type25  Feature  Integer        None   \n",
            "36                         Soil_Type26  Feature  Integer        None   \n",
            "37                         Soil_Type27  Feature  Integer        None   \n",
            "38                         Soil_Type28  Feature  Integer        None   \n",
            "39                         Soil_Type29  Feature  Integer        None   \n",
            "40                         Soil_Type30  Feature  Integer        None   \n",
            "41                         Soil_Type31  Feature  Integer        None   \n",
            "42                         Soil_Type32  Feature  Integer        None   \n",
            "43                         Soil_Type33  Feature  Integer        None   \n",
            "44                         Soil_Type34  Feature  Integer        None   \n",
            "45                         Soil_Type35  Feature  Integer        None   \n",
            "46                         Soil_Type36  Feature  Integer        None   \n",
            "47                         Soil_Type37  Feature  Integer        None   \n",
            "48                         Soil_Type38  Feature  Integer        None   \n",
            "49                         Soil_Type39  Feature  Integer        None   \n",
            "50                         Soil_Type40  Feature  Integer        None   \n",
            "51                          Cover_Type   Target  Integer        None   \n",
            "52                    Wilderness_Area2  Feature  Integer        None   \n",
            "53                    Wilderness_Area3  Feature  Integer        None   \n",
            "54                    Wilderness_Area4  Feature  Integer        None   \n",
            "\n",
            "   description units missing_values  \n",
            "0         None  None             no  \n",
            "1         None  None             no  \n",
            "2         None  None             no  \n",
            "3         None  None             no  \n",
            "4         None  None             no  \n",
            "5         None  None             no  \n",
            "6         None  None             no  \n",
            "7         None  None             no  \n",
            "8         None  None             no  \n",
            "9         None  None             no  \n",
            "10        None  None             no  \n",
            "11        None  None             no  \n",
            "12        None  None             no  \n",
            "13        None  None             no  \n",
            "14        None  None             no  \n",
            "15        None  None             no  \n",
            "16        None  None             no  \n",
            "17        None  None             no  \n",
            "18        None  None             no  \n",
            "19        None  None             no  \n",
            "20        None  None             no  \n",
            "21        None  None             no  \n",
            "22        None  None             no  \n",
            "23        None  None             no  \n",
            "24        None  None             no  \n",
            "25        None  None             no  \n",
            "26        None  None             no  \n",
            "27        None  None             no  \n",
            "28        None  None             no  \n",
            "29        None  None             no  \n",
            "30        None  None             no  \n",
            "31        None  None             no  \n",
            "32        None  None             no  \n",
            "33        None  None             no  \n",
            "34        None  None             no  \n",
            "35        None  None             no  \n",
            "36        None  None             no  \n",
            "37        None  None             no  \n",
            "38        None  None             no  \n",
            "39        None  None             no  \n",
            "40        None  None             no  \n",
            "41        None  None             no  \n",
            "42        None  None             no  \n",
            "43        None  None             no  \n",
            "44        None  None             no  \n",
            "45        None  None             no  \n",
            "46        None  None             no  \n",
            "47        None  None             no  \n",
            "48        None  None             no  \n",
            "49        None  None             no  \n",
            "50        None  None             no  \n",
            "51        None  None             no  \n",
            "52        None  None             no  \n",
            "53        None  None             no  \n",
            "54        None  None             no  \n"
          ]
        }
      ],
      "source": [
        "#!pip install ucimlrepo\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "covertype = fetch_ucirepo(id=31)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = covertype.data.features\n",
        "y = covertype.data.targets\n",
        "\n",
        "df_combined = X.copy()\n",
        "df_combined['Cover_Type'] = y['Cover_Type']\n",
        "\n",
        "# metadata\n",
        "print(covertype.metadata)\n",
        "\n",
        "# variable information\n",
        "print(covertype.variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S_Ze9NTrKUw"
      },
      "source": [
        "# Check-in Week 8/9/10\n",
        "\n",
        "Here we will use a neural network for multiclass classification. The response variable here is the forest cover type\n",
        "\n",
        "For this dataset, we will use a normal deep neural network\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PfVgOy-ms5tu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# # Uses GPU runtime\n",
        "# device = torch.device(\"cuda:0\")\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Extremely simple model architecture\n",
        "model = nn.Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add_module(\"Input\", nn.Linear(in_features = X.shape[1], out_features = 1024))\n",
        "\n",
        "# Hidden layers\n",
        "model.add_module(\"Hidden Layer 1\", nn.Linear(in_features=1024, out_features=1024))\n",
        "model.add_module(\"Activation 1\", nn.Sigmoid())\n",
        "model.add_module(\"Hidden Layer 2\", nn.Linear(in_features=1024, out_features=1024))  \n",
        "model.add_module(\"Activation 2\", nn.Sigmoid())\n",
        "\n",
        "# Add dropout for regularization\n",
        "model.add_module(\"Dropout\", nn.Dropout(p=0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add_module(\"Output\", nn.Linear(in_features=1024, out_features = len(np.unique(y))))\n",
        "# model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2Vu9G4BZFq99"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "\n",
        "# Shift the y labels to start from 0 (if this doesn't happen, PyTorch can't train)\n",
        "y = y - 1\n",
        "\n",
        "# Convert Trees Pandas DataFrame to Torch Tensors\n",
        "# Scaled the data to minimize effect of features with larger ranges (such as distance to hydrology)\n",
        "X_tensor = torch.tensor(StandardScaler().fit_transform(X.to_numpy()), dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y.to_numpy().flatten(), dtype=torch.long)\n",
        "\n",
        "# Split dataset into training, validation and testing sets\n",
        "# Stratify the y-data to preserve class distribution\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_tensor, y_tensor, test_size=0.3, random_state=42, stratify=y_tensor)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Convert to DataLoader for batching\n",
        "train_dl = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
        "val_dl = DataLoader(val_dataset, batch_size = batch_size, shuffle=False)\n",
        "test_dl = DataLoader(test_dataset, batch_size = batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXPCbUY8FyCV",
        "outputId": "036a0472-6d9d-4b1d-b8cd-665a16e2ab61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 accuracy: 0.7828 val_accuracy: 0.8508\n",
            "Epoch 2 accuracy: 0.8621 val_accuracy: 0.8769\n",
            "Epoch 3 accuracy: 0.8825 val_accuracy: 0.8932\n",
            "Epoch 4 accuracy: 0.8916 val_accuracy: 0.8968\n",
            "Epoch 5 accuracy: 0.8968 val_accuracy: 0.9048\n",
            "Epoch 6 accuracy: 0.9007 val_accuracy: 0.9073\n",
            "Epoch 7 accuracy: 0.9034 val_accuracy: 0.9082\n",
            "Epoch 8 accuracy: 0.9061 val_accuracy: 0.9106\n",
            "Epoch 9 accuracy: 0.9065 val_accuracy: 0.9066\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "\n",
        "# We will use the cross entropy loss function for multiclass\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use standard optimizer, Adam optimizer for backpropagation calculations\n",
        "# Fix the learning rate for now\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "# Our training function (just the same thing from the MNIST notebook)\n",
        "def train(model, num_epochs, train_dl, valid_dl):\n",
        "    loss_hist_train = [0] * num_epochs\n",
        "    accuracy_hist_train = [0] * num_epochs\n",
        "    loss_hist_valid = [0] * num_epochs\n",
        "    accuracy_hist_valid = [0] * num_epochs\n",
        "\n",
        "    # Form \n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for x_batch, y_batch in train_dl:\n",
        "            # x_batch = x_batch.to(device)\n",
        "            # y_batch = y_batch.to(device)\n",
        "            pred = model(x_batch)\n",
        "            loss = loss_function(pred, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            loss_hist_train[epoch] += loss.item()*y_batch.size(0)\n",
        "            is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
        "            accuracy_hist_train[epoch] += is_correct.sum().cpu()\n",
        "\n",
        "        loss_hist_train[epoch] /= len(train_dl.dataset)\n",
        "        accuracy_hist_train[epoch] /= len(train_dl.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for x_batch, y_batch in valid_dl:\n",
        "                # x_batch = x_batch.to(device)\n",
        "                # y_batch = y_batch.to(device)\n",
        "                pred = model(x_batch)\n",
        "                loss = loss_function(pred, y_batch)\n",
        "                loss_hist_valid[epoch] += loss.item() * y_batch.size(0)\n",
        "                is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
        "                accuracy_hist_valid[epoch] += is_correct.sum().cpu()\n",
        "\n",
        "        loss_hist_valid[epoch] /= len(valid_dl.dataset)\n",
        "        accuracy_hist_valid[epoch] /= len(valid_dl.dataset)\n",
        "\n",
        "        print(f'Epoch {epoch+1} accuracy: {accuracy_hist_train[epoch]:.4f} val_accuracy: {accuracy_hist_valid[epoch]:.4f}')\n",
        "    return loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid\n",
        "\n",
        "torch.manual_seed(1)\n",
        "hist_train_validation = train(model, num_epochs, train_dl, val_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1Y9OqBwpiu3"
      },
      "source": [
        "For our neural network training, we used crossentropyloss as the standard loss function as it combines logsoftmax to convert our logits into probabilities and measures how well the predicted probabilities match the true class labels.\n",
        "\n",
        "Since we have 7 forest cover types, using CrossEntropyLoss penalizes confident wrong predictions more heavily than uncertain ones and we can see that the loss decreases as the epochs increases.\n",
        "\n",
        "To preprocess our data, we normalized our features using standard scaling to ensure that all features have a mean of 0 and a standard deviation of 1. This helps the neural network converge faster and improves overall performance.\n",
        "\n",
        "For our accuracy, we need it to detect overfitting by tracking it separately on our training and validation sets.\n",
        "\n",
        "For our learning rate, we decided with learning rate of 0.001 being the best with fast convergence, stable training epochs, and a solid final validation accuracy.\n",
        "\n",
        "For our hyperparameter tuning, we chose SGD from class with momentum to get convergence and was a solid choice for neural network training. For our batch size, we chose 100 as we wanted to have faster updates with generalization and 10 epochs to see model behavior after convergence.\n",
        "\n",
        "To complete everything, we split it into a training of 70, validation of 15, and test of 15 using PyTorch's default initialization. Our forward pass computes the predictions and CrossEntropyLoss calculates the loss and our backward pass computing the gradient with SGD as our optimization."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "U0i7P_0uB2Kj",
        "vg8ifPSNTVBE",
        "ncgeXIpSqvBZ",
        "pcSD4aTfFgj7",
        "BTwnFEgdNnHG",
        "CZY1BuQwY6fK"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
